---
title: "Maximum Likelihood Estimation, Empirical Risk Minimization and Loss functions"
excerpt_separator: "<!--more-->"
categories:
  - Machine Learning
tags:
  - Maximum Likelihood
  - Empirical Risk Minimization
  - Loss Function
  - Machine Learning
---

# Why this post

A lot of machine learning newbies (including myself) got confused when we were introduced to a couple of fancy terms in this field. One example is the relationship (and difference) between maximum likelihood estimation (MLE), empirical risk minimization (ERM) and loss functions. It took me a while to Google, read textbooks and discuss with classmates before I came to a more intuitive understanding of these things, and sadly as you can tell from my efforts above, there was not a concise yet clear solution readily available now. That's what motivates me to write this post and share it here.

# Definitions first

Let's take a look at the formal definitions first.

**Maximum Likelihood Estimation (MLE)** is a concept closely related to parametric statistical model. Suppose we have an $$x$$.

Testing MathJax: $$a^2+b^2=c^2$$.
